{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "13_뉴럴네트워크_02_NN_02_MLP & XOR",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpV9Ms6pp_he"
      },
      "source": [
        "#NN_MLP(Multi-Layered Perceptron) & XOR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZeebh6CqViW"
      },
      "source": [
        "###ML 라이브러리: PyTorch(CPU 모드)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLYKJNUGX3Cf",
        "outputId": "d8d96338-9729-4606-b6cb-1d0d5454aa4e"
      },
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(777)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7eff11e60970>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2F9ieZhqtkP"
      },
      "source": [
        "##1. 데이터셋 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMtIPbwqqnnv"
      },
      "source": [
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y= torch.FloatTensor([[0], [1], [1], [0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdmMiYSVq-SQ",
        "outputId": "e10bd660-8b3b-4dda-e8ca-1e4deb93afd0"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-xLy1xHrKR8",
        "outputId": "b0fbed77-4c1a-40c5-8500-22398125fced"
      },
      "source": [
        "Y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwNRWXd9rM9b"
      },
      "source": [
        "##5. 모델 추정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLhcZtKprSq3"
      },
      "source": [
        "###NN 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh8lPkDwrSBf"
      },
      "source": [
        "linear1 = torch.nn.Linear(2, 2, bias = True) # + sigmoid: 첫번째 레이어\n",
        "linear2 = torch.nn.Linear(2, 1, bias = True) # + sigmoid: 두번째 레이어\n",
        "sigmoid = torch.nn.Sigmoid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tbD9LKYrq9l"
      },
      "source": [
        "# layer(linear + sigmoid) 연결(순서 중요!!!)\n",
        "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRgmSGaysPj2",
        "outputId": "320588b7-0379-4e1a-f65d-6da13ffbe0e8"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
              "  (1): Sigmoid()\n",
              "  (2): Linear(in_features=2, out_features=1, bias=True)\n",
              "  (3): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6myTnSkSsiC7"
      },
      "source": [
        "###모델 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bgbbu2JCsxSv"
      },
      "source": [
        "모델 학습의 환경설정: Loss Function과 Optimizer 결정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wzxyvfhvsgvd"
      },
      "source": [
        "loss = torch.nn.BCELoss() # Binary Cross Entropy Loss\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjjDH4sOtLq9",
        "outputId": "e3aff5e3-c08c-4940-d45f-be2d5fe4e6bb"
      },
      "source": [
        "for epoch in range(10000):\n",
        "\n",
        "  #Gradient Initialization\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  #Forward 계산\n",
        "  hypothesis = model(X)\n",
        "\n",
        "  #Cost: Error 계산\n",
        "  cost = loss(hypothesis, Y)\n",
        "\n",
        "  #Backpropagation\n",
        "  cost.backward()\n",
        "\n",
        "  #Cost로 가중치(W, b) 갱신\n",
        "  optimizer.step()\n",
        "\n",
        "  #100번마다 갱신 상황 출력\n",
        "  if epoch % 100 == 0:\n",
        "    print(epoch, cost.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.7434073090553284\n",
            "100 0.693165123462677\n",
            "200 0.6931577920913696\n",
            "300 0.6931517124176025\n",
            "400 0.6931463479995728\n",
            "500 0.6931411027908325\n",
            "600 0.6931357383728027\n",
            "700 0.6931294798851013\n",
            "800 0.6931220889091492\n",
            "900 0.6931126117706299\n",
            "1000 0.6930999755859375\n",
            "1100 0.6930823922157288\n",
            "1200 0.6930569410324097\n",
            "1300 0.6930190324783325\n",
            "1400 0.6929605603218079\n",
            "1500 0.6928660273551941\n",
            "1600 0.6927032470703125\n",
            "1700 0.6923960447311401\n",
            "1800 0.6917302012443542\n",
            "1900 0.6899654269218445\n",
            "2000 0.6838315725326538\n",
            "2100 0.656166672706604\n",
            "2200 0.4311005175113678\n",
            "2300 0.13489311933517456\n",
            "2400 0.0663042888045311\n",
            "2500 0.04216815158724785\n",
            "2600 0.03045385330915451\n",
            "2700 0.023665912449359894\n",
            "2800 0.01927773468196392\n",
            "2900 0.016224022954702377\n",
            "3000 0.013983809389173985\n",
            "3100 0.012273931875824928\n",
            "3200 0.010928118601441383\n",
            "3300 0.009842473082244396\n",
            "3400 0.008949032984673977\n",
            "3500 0.008201321586966515\n",
            "3600 0.0075667379423975945\n",
            "3700 0.007021686062216759\n",
            "3800 0.006548580713570118\n",
            "3900 0.006134253926575184\n",
            "4000 0.005768375005573034\n",
            "4100 0.0054430365562438965\n",
            "4200 0.005151890218257904\n",
            "4300 0.004889902658760548\n",
            "4400 0.0046528722159564495\n",
            "4500 0.004437457304447889\n",
            "4600 0.004240859299898148\n",
            "4700 0.004060701932758093\n",
            "4800 0.003895031288266182\n",
            "4900 0.0037421947345137596\n",
            "5000 0.0036007347516715527\n",
            "5100 0.003469479735940695\n",
            "5200 0.0033473046496510506\n",
            "5300 0.0032333978451788425\n",
            "5400 0.0031268750317394733\n",
            "5500 0.0030270610004663467\n",
            "5600 0.0029333550482988358\n",
            "5700 0.0028452035039663315\n",
            "5800 0.002762140706181526\n",
            "5900 0.002683777129277587\n",
            "6000 0.0026096487417817116\n",
            "6100 0.0025394847616553307\n",
            "6200 0.0024729417636990547\n",
            "6300 0.0024097643326967955\n",
            "6400 0.002349698217585683\n",
            "6500 0.0022925634402781725\n",
            "6600 0.002238075714558363\n",
            "6700 0.002186085097491741\n",
            "6800 0.0021364721469581127\n",
            "6900 0.002089011948555708\n",
            "7000 0.00204361486248672\n",
            "7100 0.0020001311786472797\n",
            "7200 0.001958396751433611\n",
            "7300 0.0019184107659384608\n",
            "7400 0.0018799942918121815\n",
            "7500 0.0018430722411721945\n",
            "7600 0.0018075549742206931\n",
            "7700 0.0017733527347445488\n",
            "7800 0.0017404207028448582\n",
            "7900 0.0017087137093767524\n",
            "8000 0.001678097527474165\n",
            "8100 0.0016485571395605803\n",
            "8200 0.001620002556592226\n",
            "8300 0.0015924491453915834\n",
            "8400 0.0015657918993383646\n",
            "8500 0.0015400308184325695\n",
            "8600 0.0015150614781305194\n",
            "8700 0.0014909137971699238\n",
            "8800 0.0014674977865070105\n",
            "8900 0.001444813678972423\n",
            "9000 0.0014228165382519364\n",
            "9100 0.0014014765620231628\n",
            "9200 0.0013806892093271017\n",
            "9300 0.0013606036081910133\n",
            "9400 0.0013410557294264436\n",
            "9500 0.001322030322626233\n",
            "9600 0.001303557539358735\n",
            "9700 0.001285637030377984\n",
            "9800 0.0012681199004873633\n",
            "9900 0.0012511102249845862\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ18un1juhEO"
      },
      "source": [
        "##6. 결과 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvoP2arbuevf",
        "outputId": "8b873ba7-4ad3-4454-86a6-b97d9622cf26"
      },
      "source": [
        "#앞서 모델 학습 과정에서는 required_grad = True로 되어있어 학습 중임을 나타낸다\n",
        "#False는 학습 중이 아님을, 모델 평가 중임을 나타낸다\n",
        "\n",
        "with torch.no_grad(): #임시로 required_grad = False로 설정하는 것과 같다\n",
        "\n",
        "  hypothesis = model(X)\n",
        "  predicted = (hypothesis > 0.5).float()\n",
        "  accuracy = (predicted == Y).float().mean()\n",
        "  \n",
        "  print('\\n Hypothesis: ', hypothesis.numpy(), '\\n Correct: ', predicted.numpy(), '\\n Accuracy: ', accuracy.item())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Hypothesis:  [[0.00106378]\n",
            " [0.9988938 ]\n",
            " [0.9988939 ]\n",
            " [0.00165883]] \n",
            " Correct:  [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]] \n",
            " Accuracy:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMV0f8V0xpnR"
      },
      "source": [
        "MLP(Multi-Layered Perceptron)은 XOR 문제를 풀 수 있다"
      ]
    }
  ]
}